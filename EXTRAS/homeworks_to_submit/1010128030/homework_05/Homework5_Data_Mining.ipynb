{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da11d8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar las librerias a utilizar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Link con los datos\n",
    "data_source_url = \"https://raw.githubusercontent.com/mhemmg/datasets/master/nlp/airline_tweets.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c07a1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para limpiar el texto de links, signos especiales y dobles espacios.\n",
    "punct = \"[!#$%&()*+,-./:;<=>?@[\\]^_`{|}~]\"\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    new_text = re.sub('https:[^,\\s]+', ' ', text)\n",
    "    new_text = re.sub('(rt|@|:)+', ' ', new_text)\n",
    "    new_text = re.sub(punct, ' ', new_text)\n",
    "    new_text = re.sub('  +', ' ', new_text)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8112009",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocesamiento de los datos, se limpian y se categorizan los sentimientos\n",
    "def preprocess(data_source_url, clean_func):\n",
    "    temp = pd.read_csv(data_source_url)\n",
    "    features_labels = temp.loc[:,('text','airline_sentiment')]\n",
    "    features_labels['airline_sentiment_bin'] = features_labels.airline_sentiment.map({'neutral': 0, 'positive': 1,'negative':2})\n",
    "    features_labels['text_clean'] = features_labels['text'].apply(lambda t: clean_func(t))\n",
    "    airline_tweets = features_labels[['text_clean','airline_sentiment_bin']]\n",
    "    return airline_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e295adec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_clean</th>\n",
       "      <th>airline_sentiment_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>virginamerica what dhepburn said</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>virginamerica plus you've added commercials t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>virginamerica i didn't today must mean i need...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>virginamerica it's really aggressive to blast...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>virginamerica and it's a really big bad thing...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text_clean  airline_sentiment_bin\n",
       "0                  virginamerica what dhepburn said                       0\n",
       "1   virginamerica plus you've added commercials t...                      1\n",
       "2   virginamerica i didn't today must mean i need...                      0\n",
       "3   virginamerica it's really aggressive to blast...                      2\n",
       "4   virginamerica and it's a really big bad thing...                      2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tabla de datos final\n",
    "airline_tweets = preprocess(data_source_url, clean_text)\n",
    "airline_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7695ac27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenamiento y testeo con random_state fijo para TextBlob y Azure\n",
    "X_train, X_test, y_train, y_test = train_test_split(airline_tweets['text_clean'], airline_tweets['airline_sentiment_bin'], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6dd17b",
   "metadata": {},
   "source": [
    "## TextBlob\n",
    "\n",
    "En esta sección se utiliza la librería textblob para hacer análisis de sentimientos como se aprendió en clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d34c8205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analisis de sentimientos con TextBlob aprendido en clase\n",
    "textblob_test = []\n",
    "\n",
    "#Librería\n",
    "from textblob import TextBlob\n",
    "\n",
    "for i in X_test:\n",
    "    sentiment = TextBlob(i).sentiment.polarity\n",
    "    if sentiment < 0:\n",
    "        textblob_test.append(2)\n",
    "    elif sentiment == 0:\n",
    "        textblob_test.append(0)\n",
    "    else:\n",
    "        textblob_test.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "709a20e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46209016393442626\n"
     ]
    }
   ],
   "source": [
    "#Precisión del análisis\n",
    "tbscore = accuracy_score(textblob_test,y_test)\n",
    "print(tbscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebd0e53",
   "metadata": {},
   "source": [
    "## Microsoft Azure\n",
    "\n",
    "En esta sección se utiliza el análisis de textos que provee microsoft azure para analizar los sentimientos de los datos usados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5dfc0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#key y endpoint de mi cuenta de azure\n",
    "key = \"0075b6399ea34cb29e92396d97230928\"\n",
    "endpoint = \"https://manu0221.cognitiveservices.azure.com/\"\n",
    "\n",
    "#Librerias necesarias\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "#Autenticación del cliente como dice en la documentación\n",
    "def authenticate_client():\n",
    "    ta_credential = AzureKeyCredential(key)\n",
    "    text_analytics_client = TextAnalyticsClient(\n",
    "            endpoint=endpoint, \n",
    "            credential=ta_credential)\n",
    "    return text_analytics_client\n",
    "\n",
    "client = authenticate_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a86bfc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analisi de sentimientos con azure siguiendo indicaciones de la documentación\n",
    "azure_test = []\n",
    "X_test_new = []\n",
    "\n",
    "for i in X_test:\n",
    "    X_test_new.append(i)\n",
    "result = []\n",
    "\n",
    "for i in np.arange(0,len(X_test_new),10):\n",
    "    result.append(client.analyze_sentiment(X_test_new[i:i+10]))\n",
    "\n",
    "for doc_result in result:\n",
    "    for document in doc_result:\n",
    "        sentiment = document.sentences[0].sentiment\n",
    "        if sentiment == 'positive':\n",
    "            azure_test.append(1)\n",
    "        if sentiment == 'neutral':\n",
    "            azure_test.append(0)\n",
    "        if sentiment == 'negative':\n",
    "            azure_test.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eec7ec60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.617827868852459\n"
     ]
    }
   ],
   "source": [
    "#Precisión del análisis\n",
    "mascore = accuracy_score(azure_test,y_test)\n",
    "print(mascore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920bbc88",
   "metadata": {},
   "source": [
    "## Sklearn\n",
    "\n",
    "En esta sección se utilizan distintos métodos de sklearn para análizar los datos. Se utilizan los métodos con parámentros predeterminados para encontrar cuál es el que da mejor resultado, a este se le varían los parámetros para encontrar sus funciones óptimas para este problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "412208f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorización del texto de los datos y división en entrenamiento y testeo\n",
    "#con mismo random_state al usado anteriormente\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_vec = vectorizer.fit_transform(airline_tweets['text_clean']).toarray()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vec, airline_tweets['airline_sentiment_bin'], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aeb026f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Métodos de clasificación a probar\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fb94b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6970628415300546\n"
     ]
    }
   ],
   "source": [
    "knc = KNeighborsClassifier()\n",
    "knc.fit(X_train,y_train)\n",
    "kncscore = knc.score(X_test,y_test)\n",
    "print(kncscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd651657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.667691256830601\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "clfscore = clf.score(X_test,y_test)\n",
    "print(clfscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25958a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7404371584699454\n"
     ]
    }
   ],
   "source": [
    "rfc  = RandomForestClassifier()\n",
    "rfc.fit(X_train,y_train)\n",
    "rfcscore = rfc.score(X_test,y_test)\n",
    "print(rfcscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a9b3f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.725068306010929\n"
     ]
    }
   ],
   "source": [
    "abc = AdaBoostClassifier()\n",
    "abc.fit(X_train,y_train)\n",
    "abcscore = abc.score(X_test,y_test)\n",
    "print(abcscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa4fe09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5105874316939891\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,y_train)\n",
    "gnbscore = gnb.score(X_test,y_test)\n",
    "print(gnbscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f33167b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Variación de parámetros, esta celda es muy lenta, no se recomienda ejecutar\n",
    "# model = RandomForestClassifier()\n",
    "# grid = dict()\n",
    "# grid['criterion'] = np.array(['gini','entropy','log_loss'])\n",
    "# grid['max_features'] = np.array(['log2','sqrt',None])\n",
    "# search = GridSearchCV(model,grid,scoring='neg_mean_absolute_error', n_jobs=None)\n",
    "# results = search.fit(X_train, y_train)\n",
    "# print('Config: %s' % results.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a76bf0",
   "metadata": {},
   "source": [
    "## Comparación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f01d9f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [['TextBlob',tbscore*100],['Microsoft Azure',mascore*100], ['GaussianNB',gnbscore*100],['DecisionTreeClassifier',clfscore*100],['KNeighborsClassifier',kncscore*100],['AdaBoostClassifier',abcscore*100],['RandomForestClassifier',rfcscore*100]]\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Método', 'Precisión %'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db9086e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Método</th>\n",
       "      <th>Precisión %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TextBlob</td>\n",
       "      <td>46.209016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Microsoft Azure</td>\n",
       "      <td>61.782787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>51.058743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>66.769126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>69.706284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>72.506831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>74.043716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Método  Precisión %\n",
       "0                TextBlob    46.209016\n",
       "1         Microsoft Azure    61.782787\n",
       "2              GaussianNB    51.058743\n",
       "3  DecisionTreeClassifier    66.769126\n",
       "4    KNeighborsClassifier    69.706284\n",
       "5      AdaBoostClassifier    72.506831\n",
       "6  RandomForestClassifier    74.043716"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0380956",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "1. Los métodos pre-entrenados ofrecen una forma rápida de clasificar datos sin necesidad de poseer con un dataset previo de gran amplitud. Tanto TextBlob como la herramienta ofrecida por Microsoft Azure son buenas.\n",
    "\n",
    "2. De tener que entrenar los modelos por cuenta propia es importante conoscer las estructuras de los métodos ofrecidos por sklearn y así deducir cuál se encaja mejor a los datos que se están manejando en el momento.\n",
    "\n",
    "3. Los métodos de limpieza de datos pueden cambiar en gran medida os resultados obtenidos, es importante realizar estudios a mayor profundidad de esto."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
